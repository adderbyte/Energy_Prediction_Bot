{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for data frame analysis\n",
    "import pandas as pd \n",
    "\n",
    "# for mathematical operations\n",
    "import numpy as np \n",
    "\n",
    "# imports below are for plotly \n",
    "import ipywidgets as widgets\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.offline.init_notebook_mode(connected=True)   # for offline mode use\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as offline\n",
    "\n",
    "\n",
    "# matplotlib library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For Normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For statistical test\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Split data set into training and test set\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# SVN module\n",
    "from sklearn import svm\n",
    "\n",
    "# Kernel Functions used \n",
    "from sklearn.metrics.pairwise import rbf_kernel,laplacian_kernel\n",
    "\n",
    "# module for chi square test\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "\n",
    "# For dictionary \n",
    "from collections import defaultdict\n",
    "\n",
    "# for use of tensorflow\n",
    "import tensorflow as tf\n",
    "#from tensorflow.nn.rnn import *\n",
    "from tensorflow.python.ops  import *\n",
    "\n",
    "# for scaling arrays\n",
    "from sklearn.preprocessing import MaxAbsScaler,MinMaxScaler\n",
    "\n",
    "import random\n",
    "\n",
    "# config file\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# auto reload\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "# for random sampling of validation set\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# load config file\n",
    "try:\n",
    "    with open(\"../config.yml\", 'r') as ymlfile:\n",
    "            cfg = yaml.safe_load(ymlfile)\n",
    "except (IOError):\n",
    "    print('config file is required. Put config file in current directory')\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working directory\n",
    "cwd = os.getcwd()\n",
    "# set the base directory. base directo\n",
    "BASE_DIR = os.path.join( os.path.dirname( cwd), '' )\n",
    "# test path\n",
    "testpath= BASE_DIR + cfg['cleanedtest']['TargetDir'] #+cfg['rawdatapath']['validationDataName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will Load only the zero meter data set \n",
    "# same syntax applied for other data set\n",
    "#meterOneDataLOaded= pd.read_csv('/Users/maya/Downloads/meterZeroTestData.csv')\n",
    "testdata= pd.read_feather('leak.feather')\n",
    "# all meter types data set could be analysed in same manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  meter_reading  timestamp\n",
       "0            0    0.0            0.0 2016-01-01\n",
       "1            1    0.0            0.0 2016-01-01\n",
       "2            2    0.0            0.0 2016-01-01\n",
       "3            3    0.0            0.0 2016-01-01\n",
       "4            4    0.0            0.0 2016-01-01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.head() # iew data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id               int64\n",
       "meter                   float64\n",
       "meter_reading           float64\n",
       "timestamp        datetime64[ns]\n",
       "year                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the year and later drop 2016 because it is in train data\n",
    "testdata['year'] = pd.DatetimeIndex(testdata['timestamp']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data cleaned to extract 2017 and 2018\n",
    "cleantest = pd.DataFrame(testdata.loc[testdata['year'].isin([2017,2018]) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraxt for meter zero\n",
    "cleantest2 =  pd.DataFrame(cleantest.loc[cleantest['meter']==0.0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up cleantest \n",
    "del cleantest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2017, 2018])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the year is 17 and 18\n",
    "cleantest2.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm only meter zero is present \n",
    "cleantest2.meter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read building data\n",
    "building = pd.read_csv('building_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with building data set\n",
    "cleantest2 = cleantest2.merge(building, on = 'building_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather data for test data\n",
    "weathertest = pd.read_csv('weather_test.csv')\n",
    "# change weather timestamp from type object to date time \n",
    "weathertest['timestamp'] =  pd.to_datetime(weathertest['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather data to the test data\n",
    "cleantest2 = cleantest2.merge(weathertest, on = ['site_id', 'timestamp'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['building_id',\n",
       " 'meter',\n",
       " 'meter_reading',\n",
       " 'timestamp',\n",
       " 'year',\n",
       " 'site_id',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'floor_count',\n",
       " 'air_temperature',\n",
       " 'cloud_coverage',\n",
       " 'dew_temperature',\n",
       " 'precip_depth_1_hr',\n",
       " 'sea_level_pressure',\n",
       " 'wind_direction',\n",
       " 'wind_speed']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column values \n",
    "cleantest2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store column as list\n",
    "columns = cleantest2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2017, 2018], dtype='int64', name='timestamp')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the unique time stamp present\n",
    "pd.DatetimeIndex(cleantest2['timestamp']).year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                 0\n",
       "meter                       0\n",
       "meter_reading               0\n",
       "timestamp                   0\n",
       "year                        0\n",
       "site_id                     0\n",
       "primary_use                 0\n",
       "square_feet                 0\n",
       "year_built            1046356\n",
       "floor_count           5217517\n",
       "air_temperature         32489\n",
       "cloud_coverage        3472356\n",
       "dew_temperature         33058\n",
       "precip_depth_1_hr     1690572\n",
       "sea_level_pressure     136913\n",
       "wind_direction         282431\n",
       "wind_speed              32923\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose windpseed because it has fewer null values\n",
    "# dont rerun this , takes time\n",
    "cleantest2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2017-01-01    11.7\n",
       "Name: dew_temperature, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "cleantest2['dew_temperature'][1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "\n",
    "finaltest = cleantest2[['timestamp','building_id','meter_reading','square_feet', 'air_temperature','primary_use','site_id','dew_temperature']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del clean test 2\n",
    "del cleantest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reset the index so that time is no longer the index\n",
    "# the index is now  numbers \n",
    "#finaltest.reset_index(level=0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrac year month and day\n",
    "\n",
    "finaltest['month'] = pd.DatetimeIndex(finaltest['timestamp']).month\n",
    "finaltest['day'] = pd.DatetimeIndex(finaltest['timestamp']).day\n",
    "finaltest['hour'] = pd.DatetimeIndex(finaltest['timestamp']).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp              0\n",
       "building_id            0\n",
       "meter_reading          0\n",
       "square_feet            0\n",
       "air_temperature    32489\n",
       "primary_use            0\n",
       "site_id                0\n",
       "dew_temperature    33058\n",
       "month                  0\n",
       "day                    0\n",
       "hour                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "finaltest.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp          datetime64[ns]\n",
       "building_id                 int64\n",
       "meter_reading             float64\n",
       "square_feet                 int64\n",
       "air_temperature           float64\n",
       "primary_use                object\n",
       "site_id                     int64\n",
       "dew_temperature           float64\n",
       "month                       int64\n",
       "day                         int64\n",
       "hour                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "finaltest.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Artefacts Added\n",
    "\n",
    "Since there are fewer site ids this will cause the feature or columns to be\n",
    "lesser.\n",
    "In effect one needs fake data but the fake data will be skipped during prediction\n",
    "of values. That is why they have been assined values of -400.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the site ids to be added\n",
    "sites_id_not_in_data =  [3,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# the time stamp to be used \n",
    "year =2019\n",
    "month = 1 # january\n",
    "day = 1\n",
    "hour=2\n",
    "# loop through add data to  index , reindex and continue\n",
    "for i in sites_id_not_in_data:\n",
    "    finaltest.loc[-1] = [ pd.Timestamp(year, month, day, 12),2, 0.,-4000000.,0.,'Education',i,0.,month,day,hour]  # adding a row\n",
    "    finaltest.index = finaltest.index + 1  # shifting index\n",
    "    finaltest = finaltest.sort_index()  # sorting by index\n",
    "    day +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7512486, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape after appending\n",
    "finaltest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  3,  0,  1,  2,  4, 15])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all site id now present\n",
    "finaltest.site_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finaltest = pd.read_csv('zerodaytest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Education', 'Lodging/residential', 'Office',\n",
       "       'Entertainment/public assembly', 'Other', 'Retail', 'Parking',\n",
       "       'Public services', 'Warehouse/storage', 'Food sales and service',\n",
       "       'Religious worship', 'Healthcare', 'Utility', 'Technology/science'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the primary use manufacturing and services are absent\n",
    "finaltest.primary_use.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pry_id_use_in_data =  ['Manufacturing/industrial','Services']\n",
    "\n",
    "# the time stamp to be used \n",
    "year =2019\n",
    "month = 1 # january\n",
    "day = 19\n",
    "hour=2\n",
    "# loop through add data to  index , reindex and continue\n",
    "for i in pry_id_use_in_data:\n",
    "    finaltest.loc[-1] = [ pd.Timestamp(year, month, day, 12),2 ,0.,-4000000.,0.,i,15,0.,month,day,hour]  # adding a row\n",
    "    finaltest.index = finaltest.index + 1  # shifting index\n",
    "    finaltest = finaltest.sort_index()  # sorting by index\n",
    "    day +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time as index\n",
    "#finaltest.set_index('timestamp',inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "#finaltest.to_csv('zerodaytest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'building_id', 'meter_reading', 'square_feet',\n",
       "       'air_temperature', 'primary_use', 'site_id', 'dew_temperature', 'month',\n",
       "       'day', 'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dummies\n",
    "finaltest = pd.get_dummies(finaltest, columns=[\"primary_use\",\"site_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7512488, 38)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape is now correct \n",
    "# delete the meter_reading since it is the target\n",
    "finaltest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward filling missing values since values from previous timestamp should\n",
    "# ideally be similar to the next one. (temperature today and tomorrow should be quite similar)\n",
    "finaltest['air_temperature'].fillna(method='ffill', inplace=True)\n",
    "finaltest['dew_temperature'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove artefact values\n",
    "finaltest = finaltest[finaltest.square_feet !=-4000000.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true meter readings, building id, timestamp\n",
    "test_readings = finaltest[['meter_reading','building_id','timestamp']].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to path\n",
    "test_readings.to_csv(testpath +  cfg['cleanedtest']['testDatasetName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building test readings\n",
    "del test_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building building id from finnaltest\n",
    "del finaltest['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re index the dataset\n",
    "finaltest.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test data\n",
    "finaltest.to_feather(testpath +  cfg['cleanedtest']['testFeatureSet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special cleaning for LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete timestamp and meter readings\n",
    "del finaltest['timestamp']\n",
    "del finaltest['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize(array):\n",
    "    '''\n",
    "    Standardize an array along eachcolumn (each feature that is)\n",
    "    '''\n",
    "    transformer = MaxAbsScaler().fit(array)\n",
    "    output = transformer.transform(array)\n",
    "    return  np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "lstmtest =  Standardize(finaltest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(testpath + cfg['cleanedtest']['LSTMtestFeatureSet'] , lstmtest) # save\n",
    "#new_num_arr = np.load('data.npy') # load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
