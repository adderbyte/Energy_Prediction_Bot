{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Lukman copyright \n",
    "# MIT Licence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for data frame analysis\n",
    "import pandas as pd \n",
    "\n",
    "# for mathematical operations\n",
    "import numpy as np \n",
    "\n",
    "# imports below are for plotly \n",
    "import ipywidgets as widgets\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.offline.init_notebook_mode(connected=True)   # for offline mode use\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as offline\n",
    "\n",
    "\n",
    "# matplotlib library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For Normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For statistical test\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Split data set into training and test set\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# SVN module\n",
    "from sklearn import svm\n",
    "\n",
    "# Kernel Functions used \n",
    "from sklearn.metrics.pairwise import rbf_kernel,laplacian_kernel\n",
    "\n",
    "# module for chi square test\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "\n",
    "# For dictionary \n",
    "from collections import defaultdict\n",
    "\n",
    "# for use of tensorflow\n",
    "import tensorflow as tf\n",
    "#from tensorflow.nn.rnn import *\n",
    "from tensorflow.python.ops  import *\n",
    "\n",
    "# for scaling arrays\n",
    "from sklearn.preprocessing import MaxAbsScaler,MinMaxScaler\n",
    "\n",
    "\n",
    "# for random sampling of validation set\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will Load only the zero meter data set \n",
    "# same syntax applied for other data set\n",
    "meterOneDataLOaded= pd.read_csv('meterOneTrainData.csv')\n",
    "# all meter types data set could be analysed in same manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>98829</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>4.5719</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>72102</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  building_id  meter            timestamp  meter_reading  \\\n",
       "1           1          162      1  2016-01-01 00:00:00         0.0000   \n",
       "2           2          163      1  2016-01-01 00:00:00         4.5719   \n",
       "\n",
       "   site_id primary_use  square_feet  year_built  floor_count  air_temperature  \\\n",
       "1        2   Education        98829      1968.0          NaN             15.6   \n",
       "2        2   Education        72102      1970.0          NaN             15.6   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "1             6.0             -5.6                NaN              1015.3   \n",
       "2             6.0             -5.6                NaN              1015.3   \n",
       "\n",
       "   wind_direction  wind_speed  \n",
       "1           270.0         3.6  \n",
       "2           270.0         3.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meterOneDataLOaded[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete column unnmaed\n",
    "del meterOneDataLOaded['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['building_id',\n",
       " 'meter',\n",
       " 'timestamp',\n",
       " 'meter_reading',\n",
       " 'site_id',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'floor_count',\n",
       " 'air_temperature',\n",
       " 'cloud_coverage',\n",
       " 'dew_temperature',\n",
       " 'precip_depth_1_hr',\n",
       " 'sea_level_pressure',\n",
       " 'wind_direction',\n",
       " 'wind_speed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column values \n",
    "meterOneDataLOaded.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store column as list\n",
    "columns = meterOneDataLOaded.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                 0\n",
       "meter                       0\n",
       "timestamp                   0\n",
       "meter_reading               0\n",
       "site_id                     0\n",
       "primary_use                 0\n",
       "square_feet                 0\n",
       "year_built            2819559\n",
       "floor_count           3972549\n",
       "air_temperature         23502\n",
       "cloud_coverage        1742296\n",
       "dew_temperature         24341\n",
       "precip_depth_1_hr      541565\n",
       "sea_level_pressure     105047\n",
       "wind_direction         402544\n",
       "wind_speed              37330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get null values per column in the data set\n",
    "meterOneDataLOaded.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chnage to time sta\n",
    "meterOneDataLOaded['timestamp'] =  pd.to_datetime(meterOneDataLOaded['timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2016], dtype='int64', name='timestamp')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the unique time stamp present\n",
    "pd.DatetimeIndex(meterOneDataLOaded['timestamp']).year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                    int64\n",
       "meter                          int64\n",
       "timestamp             datetime64[ns]\n",
       "meter_reading                float64\n",
       "site_id                        int64\n",
       "primary_use                   object\n",
       "square_feet                    int64\n",
       "year_built                   float64\n",
       "floor_count                  float64\n",
       "air_temperature              float64\n",
       "cloud_coverage               float64\n",
       "dew_temperature              float64\n",
       "precip_depth_1_hr            float64\n",
       "sea_level_pressure           float64\n",
       "wind_direction               float64\n",
       "wind_speed                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meterOneDataLOaded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                 0\n",
       "meter                       0\n",
       "timestamp                   0\n",
       "meter_reading               0\n",
       "site_id                     0\n",
       "primary_use                 0\n",
       "square_feet                 0\n",
       "year_built            2819559\n",
       "floor_count           3972549\n",
       "air_temperature         23502\n",
       "cloud_coverage        1742296\n",
       "dew_temperature         24341\n",
       "precip_depth_1_hr      541565\n",
       "sea_level_pressure     105047\n",
       "wind_direction         402544\n",
       "wind_speed              37330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose windpseed because it has fewer null values\n",
    "meterOneDataLOaded.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time stamp as index \n",
    "meterOneDataLOaded.set_index('timestamp',inplace=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2016-01-01   -5.6\n",
       "Name: dew_temperature, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meterOneDataLOaded['dew_temperature'][1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a subset of the data has been copied to use to test the visualizer function\n",
    "# use the full data set if space is available and system is fast\n",
    "\n",
    "train_test = meterOneDataLOaded[['meter_reading', 'square_feet', 'air_temperature','primary_use','site_id','dew_temperature']][1:30000].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reset the index so that time is no longer the index\n",
    "# the index is now  numbers \n",
    "train_test.reset_index(level=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2016], dtype='int64', name='timestamp')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only 2016 data is represented here as usual\n",
    "pd.DatetimeIndex(train_test['timestamp']).year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrac year month and day\n",
    "train_test['year'] = pd.DatetimeIndex(train_test['timestamp']).year\n",
    "train_test['month'] = pd.DatetimeIndex(train_test['timestamp']).month\n",
    "train_test['day'] = pd.DatetimeIndex(train_test['timestamp']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp             0\n",
       "meter_reading         0\n",
       "square_feet           0\n",
       "air_temperature    1836\n",
       "primary_use           0\n",
       "site_id               0\n",
       "dew_temperature    1836\n",
       "year                  0\n",
       "month                 0\n",
       "day                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "train_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp          datetime64[ns]\n",
       "meter_reading             float64\n",
       "square_feet                 int64\n",
       "air_temperature           float64\n",
       "primary_use                object\n",
       "site_id                     int64\n",
       "dew_temperature           float64\n",
       "year                        int64\n",
       "month                       int64\n",
       "day                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "train_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward filling missing values since values from previous timestamp should\n",
    "# ideally be similar to the next one. (temperature today and tomorrow should be quite similar)\n",
    "train_test['air_temperature'].fillna(method='ffill', inplace=True)\n",
    "train_test['dew_temperature'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete year we wont use the year information in the model\n",
    "del train_test['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode site id and primary use\n",
    "train_test = pd.get_dummies(train_test, columns=[\"primary_use\",\"site_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>primary_use_Education</th>\n",
       "      <th>primary_use_Entertainment/public assembly</th>\n",
       "      <th>primary_use_Food sales and service</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use_Utility</th>\n",
       "      <th>site_id_2</th>\n",
       "      <th>site_id_6</th>\n",
       "      <th>site_id_7</th>\n",
       "      <th>site_id_9</th>\n",
       "      <th>site_id_10</th>\n",
       "      <th>site_id_11</th>\n",
       "      <th>site_id_13</th>\n",
       "      <th>site_id_14</th>\n",
       "      <th>site_id_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>98829</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.5719</td>\n",
       "      <td>72102</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>209.8860</td>\n",
       "      <td>553210</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>86323</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>51.5570</td>\n",
       "      <td>183460</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  meter_reading  square_feet  air_temperature  dew_temperature  \\\n",
       "0 2016-01-01         0.0000        98829             15.6             -5.6   \n",
       "1 2016-01-01         4.5719        72102             15.6             -5.6   \n",
       "2 2016-01-01       209.8860       553210             15.6             -5.6   \n",
       "3 2016-01-01         0.0000        86323             15.6             -5.6   \n",
       "4 2016-01-01        51.5570       183460             15.6             -5.6   \n",
       "\n",
       "   month  day  primary_use_Education  \\\n",
       "0      1    1                      1   \n",
       "1      1    1                      1   \n",
       "2      1    1                      0   \n",
       "3      1    1                      0   \n",
       "4      1    1                      1   \n",
       "\n",
       "   primary_use_Entertainment/public assembly  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   primary_use_Food sales and service     ...      primary_use_Utility  \\\n",
       "0                                   0     ...                        0   \n",
       "1                                   0     ...                        0   \n",
       "2                                   0     ...                        0   \n",
       "3                                   0     ...                        0   \n",
       "4                                   0     ...                        0   \n",
       "\n",
       "   site_id_2  site_id_6  site_id_7  site_id_9  site_id_10  site_id_11  \\\n",
       "0          1          0          0          0           0           0   \n",
       "1          1          0          0          0           0           0   \n",
       "2          1          0          0          0           0           0   \n",
       "3          1          0          0          0           0           0   \n",
       "4          1          0          0          0           0           0   \n",
       "\n",
       "   site_id_13  site_id_14  site_id_15  \n",
       "0           0           0           0  \n",
       "1           0           0           0  \n",
       "2           0           0           0  \n",
       "3           0           0           0  \n",
       "4           0           0           0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time as index\n",
    "train_test.set_index('timestamp',inplace=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>primary_use_Education</th>\n",
       "      <th>primary_use_Entertainment/public assembly</th>\n",
       "      <th>primary_use_Food sales and service</th>\n",
       "      <th>primary_use_Healthcare</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use_Utility</th>\n",
       "      <th>site_id_2</th>\n",
       "      <th>site_id_6</th>\n",
       "      <th>site_id_7</th>\n",
       "      <th>site_id_9</th>\n",
       "      <th>site_id_10</th>\n",
       "      <th>site_id_11</th>\n",
       "      <th>site_id_13</th>\n",
       "      <th>site_id_14</th>\n",
       "      <th>site_id_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4.5719</td>\n",
       "      <td>72102</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            meter_reading  square_feet  air_temperature  dew_temperature  \\\n",
       "timestamp                                                                  \n",
       "2016-01-01         4.5719        72102             15.6             -5.6   \n",
       "\n",
       "            month  day  primary_use_Education  \\\n",
       "timestamp                                       \n",
       "2016-01-01      1    1                      1   \n",
       "\n",
       "            primary_use_Entertainment/public assembly  \\\n",
       "timestamp                                               \n",
       "2016-01-01                                          0   \n",
       "\n",
       "            primary_use_Food sales and service  primary_use_Healthcare  \\\n",
       "timestamp                                                                \n",
       "2016-01-01                                   0                       0   \n",
       "\n",
       "               ...      primary_use_Utility  site_id_2  site_id_6  site_id_7  \\\n",
       "timestamp      ...                                                             \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "\n",
       "            site_id_9  site_id_10  site_id_11  site_id_13  site_id_14  \\\n",
       "timestamp                                                               \n",
       "2016-01-01          0           0           0           0           0   \n",
       "\n",
       "            site_id_15  \n",
       "timestamp               \n",
       "2016-01-01           0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meter_reading', 'square_feet', 'air_temperature', 'dew_temperature',\n",
       "       'month', 'day', 'primary_use_Education',\n",
       "       'primary_use_Entertainment/public assembly',\n",
       "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
       "       'primary_use_Lodging/residential',\n",
       "       'primary_use_Manufacturing/industrial', 'primary_use_Office',\n",
       "       'primary_use_Other', 'primary_use_Parking',\n",
       "       'primary_use_Public services', 'primary_use_Religious worship',\n",
       "       'primary_use_Retail', 'primary_use_Technology/science',\n",
       "       'primary_use_Utility', 'site_id_2', 'site_id_6', 'site_id_7',\n",
       "       'site_id_9', 'site_id_10', 'site_id_11', 'site_id_13', 'site_id_14',\n",
       "       'site_id_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the predictor and featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>primary_use_Education</th>\n",
       "      <th>primary_use_Entertainment/public assembly</th>\n",
       "      <th>primary_use_Food sales and service</th>\n",
       "      <th>primary_use_Healthcare</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use_Utility</th>\n",
       "      <th>site_id_2</th>\n",
       "      <th>site_id_6</th>\n",
       "      <th>site_id_7</th>\n",
       "      <th>site_id_9</th>\n",
       "      <th>site_id_10</th>\n",
       "      <th>site_id_11</th>\n",
       "      <th>site_id_13</th>\n",
       "      <th>site_id_14</th>\n",
       "      <th>site_id_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>98829</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4.5719</td>\n",
       "      <td>72102</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>209.8860</td>\n",
       "      <td>553210</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>86323</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>51.5570</td>\n",
       "      <td>183460</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            meter_reading  square_feet  air_temperature  dew_temperature  \\\n",
       "timestamp                                                                  \n",
       "2016-01-01         0.0000        98829             15.6             -5.6   \n",
       "2016-01-01         4.5719        72102             15.6             -5.6   \n",
       "2016-01-01       209.8860       553210             15.6             -5.6   \n",
       "2016-01-01         0.0000        86323             15.6             -5.6   \n",
       "2016-01-01        51.5570       183460             15.6             -5.6   \n",
       "\n",
       "            month  day  primary_use_Education  \\\n",
       "timestamp                                       \n",
       "2016-01-01      1    1                      1   \n",
       "2016-01-01      1    1                      1   \n",
       "2016-01-01      1    1                      0   \n",
       "2016-01-01      1    1                      0   \n",
       "2016-01-01      1    1                      1   \n",
       "\n",
       "            primary_use_Entertainment/public assembly  \\\n",
       "timestamp                                               \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "\n",
       "            primary_use_Food sales and service  primary_use_Healthcare  \\\n",
       "timestamp                                                                \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "\n",
       "               ...      primary_use_Utility  site_id_2  site_id_6  site_id_7  \\\n",
       "timestamp      ...                                                             \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "\n",
       "            site_id_9  site_id_10  site_id_11  site_id_13  site_id_14  \\\n",
       "timestamp                                                               \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "\n",
       "            site_id_15  \n",
       "timestamp               \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_test[['meter_reading']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_test['meter_reading']# delete target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test = train_test.values.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-Validation Spearation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation-set (1000, 28) | Train-set (28999, 28)\n",
      "------------------------------------------------\n",
      "validation-target (1000, 1) | Train-Target (28999, 1)\n"
     ]
    }
   ],
   "source": [
    "#img_size=10;\n",
    "VALIDATION_SIZE = 1000\n",
    "\n",
    "validation_set = train_test[:VALIDATION_SIZE].values\n",
    "validation_target = target[:VALIDATION_SIZE].values\n",
    "\n",
    "train_set = train_test[VALIDATION_SIZE:].values\n",
    "train_target = target[VALIDATION_SIZE:].values\n",
    "\n",
    "print('validation-set',validation_set.shape, '|' ,'Train-set', train_set.shape)\n",
    "print('------------------------------------------------')\n",
    "print('validation-target',validation_target.shape,'|','Train-Target' ,train_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize(array):\n",
    "    '''\n",
    "    Standardize an array along eachcolumn (each feature that is)\n",
    "    '''\n",
    "    transformer = MaxAbsScaler().fit(array)\n",
    "    output = transformer.transform(array)\n",
    "    return  np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = Standardize(validation_set)\n",
    "validation_target = Standardize(validation_target)\n",
    "train_set = Standardize(train_set)\n",
    "train_target =  Standardize(train_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_set.astype(np.float64, copy=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set.astype(np.float64, copy=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_set.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_set\n",
    "    global train_target\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_set = train_set[perm]\n",
    "        train_target = train_target[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_set[start:end], train_target[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def valdation_random_sampler(validation_set, validation_target, n_validation_sample):    \n",
    "    rng = np.random.RandomState(42)  # reproducible results with a fixed seed\n",
    "    indices = random.sample(range(0, len(validation_set)-1), n_validation_sample)\n",
    "    #indices = np.arange(n_samples)\n",
    "    \n",
    "    rng.shuffle(indices)\n",
    "    #print(indices)\n",
    "    x_shuffled = validation_set[indices]\n",
    "    y_shuffled = validation_target[indices]\n",
    "    return x_shuffled,y_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= valdation_random_sampler(validation_set, validation_target,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Params\n",
    "with tf.name_scope(\"input_target_placeholders\"):    \n",
    "    input_dim = 1\n",
    "    ##The Input Layer as a Placeholder\n",
    "    #Since we will provide data sequentially, the 'batch size'\n",
    "    #is 1.\n",
    "    input_layer = tf.placeholder(tf.float32, [1, input_dim*train_set.shape[1]],name=\"input_data\")\n",
    "    correct_output = tf.placeholder(tf.float32, [input_dim],name=\"target_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-41-98a03ae2875c>:2: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f3330439198>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:From /home/cat/anaconda3/envs/cat/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"lstmLayer\",reuse=tf.AUTO_REUSE ):    \n",
    "    lstm_layer1 = rnn_cell.BasicLSTMCell(input_dim*2042,state_is_tuple=False)\n",
    "    #lstm_layer1 = rnn_cell.BasicLSTMCell(input_dim*1,state_is_tuple=True)\n",
    "\n",
    "    #The LSTM state as a Variable initialized to zeroes\n",
    "    lstm_state1 = tf.Variable(tf.zeros([1, lstm_layer1.state_size]),trainable=False,name=\"initial_state\")\n",
    "    #lstm_state1 = tf.Variable(lstm_layer1.zero_state(1,lstm_layer1.state_size[-1] ), trainable=False)\n",
    "    #Connect the input layer and initial LSTM state to the LSTM cell\n",
    "    lstm_output1, lstm_state_output1 = lstm_layer1(input_layer, lstm_state1)\n",
    "    #The LSTM state will get updated\n",
    "    outputs = lstm_state1.assign(lstm_state_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstmLayer/basic_lstm_cell/Mul_2:0' shape=(1, 2042) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(2042)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"weight_Bias_learning_rate\"):\n",
    "    global_step = tf.Variable(0, trainable=False,name=\"global_step\")\n",
    "    starter_learning_rate = 1e-6\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.8, staircase=False,name =\"Exponential_decay\")\n",
    "    ##The Regression-Output Layer\n",
    "    #The Weights and Biases matrices first\n",
    "    output_W1 = tf.Variable(tf.truncated_normal([int(lstm_output1.shape[1]), 1]),name=\"weight\")\n",
    "    output_b1 = tf.Variable(tf.truncated_normal([input_dim]),name=\"bias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"prediction\"):\n",
    "    #Compute the output\n",
    "    final_output = tf.matmul(lstm_output1, output_W1) + output_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lambda_l2_reg=0.9\n",
    "l2 = lambda_l2_reg * sum( tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables() if not (\"noreg\" in tf_var.name or \"bias\" in tf_var.name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_factor = 0.01\n",
    "with tf.name_scope(\"RMS_error\"):\n",
    "    ##Calculate the Sum-of-Squares Error\n",
    "    error = tf.pow(tf.subtract(final_output, correct_output), 2)+(bias_factor*l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"optimizer\",reuse=tf.AUTO_REUSE ):    \n",
    "    ##The Optimizer\n",
    "    #Adam works best\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary to monitor MSE\n",
    "mse=tf.summary.tensor_summary(\"errors_Summary\",error)\n",
    "# Create a summary to monitor  predictions\n",
    "prediction=tf.summary.tensor_summary(\"predictions_Summmary\", final_output)\n",
    "# Create a summary to monitor bias\n",
    "bias_vec=tf.summary.tensor_summary(\"bias\", output_b1)\n",
    "# create sumary\n",
    "#rate_vec=tf.summary.scalar(\"rate\", learning_rate)\n",
    "\n",
    "\n",
    "#histogram plot\n",
    "\n",
    "error_stats=tf.summary.histogram(\"errors_Histogram\",error)\n",
    "weight_stats=tf.summary.histogram(\"weights_Histogram\",output_W1)\n",
    "bias_stats=tf.summary.histogram(\"biases_Histogram\",output_b1)\n",
    "#learning_stats=tf.histogram_summary(\"biases_Histogram\",learning_rate)\n",
    "\n",
    "\n",
    "#merged_summary_op =  tf.merge_all_summaries()\n",
    "merged_summary_op =   tf.summary.merge([mse,prediction,bias_vec,error_stats,weight_stats,bias_stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Session\n",
    "sess = tf.Session()\n",
    "#Initialize all Variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = './lstm/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter\n",
    "train_errors = []\n",
    "train_prediction = []\n",
    "validation_errors = []\n",
    "validation_prediction= []\n",
    "display_step = 1\n",
    "VALIDATON= True\n",
    "\n",
    "n_validation_sample = 2\n",
    "writer = tf.summary.FileWriter(logs_path, graph= tf.get_default_graph())\n",
    "TRAINING_ITERATIONS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set to 20000 on local environment to get 0.99 accuracy\n",
    "TRAINING_ITERATIONS = 5\n",
    "    \n",
    "DROPOUT = 0.5\n",
    "#BATCH_SIZES = 200\n",
    "\n",
    "# set to 0 to train on all available data\n",
    "\n",
    "BATCH_SIZE= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_mse / validation_mse => 21.97 / 23.16 for step 0\n",
      "training_mse / validation_mse => 21.77 / 23.23 for step 1\n",
      "training_mse / validation_mse => 21.76 / 23.12 for step 2\n",
      "training_mse / validation_mse => 21.67 / 22.36 for step 3\n",
      "training_mse / validation_mse => 21.79 / 22.67 for step 4\n"
     ]
    }
   ],
   "source": [
    "#update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "# reset global parameters before traning/running\n",
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_set.shape[0]\n",
    "\n",
    "# run training\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "\n",
    "        #get new batch\n",
    "        batch_xs, batch_ys = next_batch(BATCH_SIZE)  \n",
    "        #print(batch_ys.shape,batch_xs.shape)\n",
    "        temp = [] # store output temporally\n",
    "        for m,n in zip(batch_xs,batch_ys):\n",
    "            #print(m.shape,n.shape)\n",
    "            # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "            _, _, network_output,errors,summary = sess.run([outputs,\n",
    "                                         train_step,\n",
    "                                         final_output,error,merged_summary_op],\n",
    "                                        feed_dict = {\n",
    "                                            input_layer: m.reshape(1,train_set.shape[1]),\n",
    "                                            correct_output: n})\n",
    "            \n",
    "        \n",
    "            writer.add_summary(summary)\n",
    "            #print(errors,network_output, n)\n",
    "            temp.append(errors)\n",
    "            train_prediction.append(network_output) # store predicted value\n",
    "            \n",
    "        error_mean = np.mean(temp)                  \n",
    "        train_errors.append(error_mean)\n",
    "               \n",
    "        if(VALIDATON):\n",
    "            val_train, val_tar = valdation_random_sampler(validation_set, validation_target, n_validation_sample)\n",
    "            temp_ = []\n",
    "            for k,l in zip(val_train,val_tar):\n",
    "                sess.run(lstm_state1.assign(tf.zeros([1, lstm_layer1.state_size])))\n",
    "\n",
    "                final_outputs, val_error = sess.run([\n",
    "                                          final_output, error],\n",
    "                                         feed_dict = {\n",
    "                                         input_layer: k.reshape(1,train_set.shape[1]),\n",
    "                                         correct_output: l})  \n",
    "                \n",
    "                validation_prediction.append(final_outputs)\n",
    "                temp_.append(val_error)\n",
    "                 \n",
    "            val_error_mean = np.mean(temp_)\n",
    "            validation_errors.append(val_error_mean)\n",
    "                            \n",
    "            if i%display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n",
    "                print('training_mse / validation_mse => %.2f / %.2f for step %d' % \n",
    "            (error_mean, val_error_mean, i))\n",
    "              \n",
    "            \n",
    "                \n",
    "        \n",
    "        # increase display_step\n",
    "        \n",
    "        # increase display_step                       \n",
    "        if i%(display_step*30) == 0 and i:\n",
    "            display_step *= 30\n",
    "        \n",
    "        # train on batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorplot = np.array(train_errors) # make errors into arrays\n",
    "errorplot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errorplot, 'o--', linewidth=2,color='orange')\n",
    "plt.title(\"Histogram  error plot\",fontweight='bold')\n",
    "plt.ylabel(\"Error\",fontweight='bold')\n",
    "plt.xlabel(\"Training epoch\",fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "LSTM works fine on Time series but one needs care so that things do not blow up.\n",
    "On a very suphiscated machine, this model could work impeccably well.\n",
    "ARIMA,SARIMA are also very powerful models but they have less representational power compared to lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
