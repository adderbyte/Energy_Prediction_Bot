{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ Lukman copyright \n",
    "# MIT Licence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for data frame analysis\n",
    "import pandas as pd \n",
    "\n",
    "# for mathematical operations\n",
    "import numpy as np \n",
    "\n",
    "# imports below are for plotly \n",
    "import ipywidgets as widgets\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.offline.init_notebook_mode(connected=True)   # for offline mode use\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as offline\n",
    "\n",
    "\n",
    "# matplotlib library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For Normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For statistical test\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Split data set into training and test set\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "# SVN module\n",
    "from sklearn import svm\n",
    "\n",
    "# Kernel Functions used \n",
    "from sklearn.metrics.pairwise import rbf_kernel,laplacian_kernel\n",
    "\n",
    "# module for chi square test\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "\n",
    "# For dictionary \n",
    "from collections import defaultdict\n",
    "\n",
    "# for use of tensorflow\n",
    "import tensorflow as tf\n",
    "#from tensorflow.nn.rnn import *\n",
    "from tensorflow.python.ops  import *\n",
    "\n",
    "# for scaling arrays\n",
    "from sklearn.preprocessing import MaxAbsScaler,MinMaxScaler\n",
    "\n",
    "\n",
    "# for random sampling of validation set\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will Load only the zero meter data set \n",
    "# same syntax applied for other data set\n",
    "meterOneDataLOaded= pd.read_csv('meterOneTrainData.csv')\n",
    "# all meter types data set could be analysed in same manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>98829</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>4.5719</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>72102</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>270.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  building_id  meter            timestamp  meter_reading  \\\n",
       "1           1          162      1  2016-01-01 00:00:00         0.0000   \n",
       "2           2          163      1  2016-01-01 00:00:00         4.5719   \n",
       "\n",
       "   site_id primary_use  square_feet  year_built  floor_count  air_temperature  \\\n",
       "1        2   Education        98829      1968.0          NaN             15.6   \n",
       "2        2   Education        72102      1970.0          NaN             15.6   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "1             6.0             -5.6                NaN              1015.3   \n",
       "2             6.0             -5.6                NaN              1015.3   \n",
       "\n",
       "   wind_direction  wind_speed  \n",
       "1           270.0         3.6  \n",
       "2           270.0         3.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meterOneDataLOaded[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete column unnmaed\n",
    "del meterOneDataLOaded['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['building_id',\n",
       " 'meter',\n",
       " 'timestamp',\n",
       " 'meter_reading',\n",
       " 'site_id',\n",
       " 'primary_use',\n",
       " 'square_feet',\n",
       " 'year_built',\n",
       " 'floor_count',\n",
       " 'air_temperature',\n",
       " 'cloud_coverage',\n",
       " 'dew_temperature',\n",
       " 'precip_depth_1_hr',\n",
       " 'sea_level_pressure',\n",
       " 'wind_direction',\n",
       " 'wind_speed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column values \n",
    "meterOneDataLOaded.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store column as list\n",
    "columns = meterOneDataLOaded.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                 0\n",
       "meter                       0\n",
       "timestamp                   0\n",
       "meter_reading               0\n",
       "site_id                     0\n",
       "primary_use                 0\n",
       "square_feet                 0\n",
       "year_built            2819559\n",
       "floor_count           3972549\n",
       "air_temperature         23502\n",
       "cloud_coverage        1742296\n",
       "dew_temperature         24341\n",
       "precip_depth_1_hr      541565\n",
       "sea_level_pressure     105047\n",
       "wind_direction         402544\n",
       "wind_speed              37330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get null values per column in the data set\n",
    "meterOneDataLOaded.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chnage to time sta\n",
    "meterOneDataLOaded['timestamp'] =  pd.to_datetime(meterOneDataLOaded['timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2016], dtype='int64', name='timestamp')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the unique time stamp present\n",
    "pd.DatetimeIndex(meterOneDataLOaded['timestamp']).year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                    int64\n",
       "meter                          int64\n",
       "timestamp             datetime64[ns]\n",
       "meter_reading                float64\n",
       "site_id                        int64\n",
       "primary_use                   object\n",
       "square_feet                    int64\n",
       "year_built                   float64\n",
       "floor_count                  float64\n",
       "air_temperature              float64\n",
       "cloud_coverage               float64\n",
       "dew_temperature              float64\n",
       "precip_depth_1_hr            float64\n",
       "sea_level_pressure           float64\n",
       "wind_direction               float64\n",
       "wind_speed                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meterOneDataLOaded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id                 0\n",
       "meter                       0\n",
       "timestamp                   0\n",
       "meter_reading               0\n",
       "site_id                     0\n",
       "primary_use                 0\n",
       "square_feet                 0\n",
       "year_built            2819559\n",
       "floor_count           3972549\n",
       "air_temperature         23502\n",
       "cloud_coverage        1742296\n",
       "dew_temperature         24341\n",
       "precip_depth_1_hr      541565\n",
       "sea_level_pressure     105047\n",
       "wind_direction         402544\n",
       "wind_speed              37330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose windpseed because it has fewer null values\n",
    "meterOneDataLOaded.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time stamp as index \n",
    "meterOneDataLOaded.set_index('timestamp',inplace=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2016-01-01   -5.6\n",
       "Name: dew_temperature, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meterOneDataLOaded['dew_temperature'][1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a subset of the data has been copied to use to test the visualizer function\n",
    "# use the full data set if space is available and system is fast\n",
    "\n",
    "train_test = meterOneDataLOaded[['meter_reading', 'square_feet', 'air_temperature','primary_use','site_id','dew_temperature']][1:30000].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reset the index so that time is no longer the index\n",
    "# the index is now  numbers \n",
    "train_test.reset_index(level=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2016], dtype='int64', name='timestamp')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only 2016 data is represented here as usual\n",
    "pd.DatetimeIndex(train_test['timestamp']).year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrac year month and day\n",
    "train_test['year'] = pd.DatetimeIndex(train_test['timestamp']).year\n",
    "train_test['month'] = pd.DatetimeIndex(train_test['timestamp']).month\n",
    "train_test['day'] = pd.DatetimeIndex(train_test['timestamp']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp             0\n",
       "meter_reading         0\n",
       "square_feet           0\n",
       "air_temperature    1836\n",
       "primary_use           0\n",
       "site_id               0\n",
       "dew_temperature    1836\n",
       "year                  0\n",
       "month                 0\n",
       "day                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "train_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp          datetime64[ns]\n",
       "meter_reading             float64\n",
       "square_feet                 int64\n",
       "air_temperature           float64\n",
       "primary_use                object\n",
       "site_id                     int64\n",
       "dew_temperature           float64\n",
       "year                        int64\n",
       "month                       int64\n",
       "day                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "train_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward filling missing values since values from previous timestamp should\n",
    "# ideally be similar to the next one. (temperature today and tomorrow should be quite similar)\n",
    "train_test['air_temperature'].fillna(method='ffill', inplace=True)\n",
    "train_test['dew_temperature'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete year we wont use the year information in the model\n",
    "del train_test['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode site id and primary use\n",
    "train_test = pd.get_dummies(train_test, columns=[\"primary_use\",\"site_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>primary_use_Education</th>\n",
       "      <th>primary_use_Entertainment/public assembly</th>\n",
       "      <th>primary_use_Food sales and service</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use_Utility</th>\n",
       "      <th>site_id_2</th>\n",
       "      <th>site_id_6</th>\n",
       "      <th>site_id_7</th>\n",
       "      <th>site_id_9</th>\n",
       "      <th>site_id_10</th>\n",
       "      <th>site_id_11</th>\n",
       "      <th>site_id_13</th>\n",
       "      <th>site_id_14</th>\n",
       "      <th>site_id_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>98829</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.5719</td>\n",
       "      <td>72102</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>209.8860</td>\n",
       "      <td>553210</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>86323</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>51.5570</td>\n",
       "      <td>183460</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  meter_reading  square_feet  air_temperature  dew_temperature  \\\n",
       "0 2016-01-01         0.0000        98829             15.6             -5.6   \n",
       "1 2016-01-01         4.5719        72102             15.6             -5.6   \n",
       "2 2016-01-01       209.8860       553210             15.6             -5.6   \n",
       "3 2016-01-01         0.0000        86323             15.6             -5.6   \n",
       "4 2016-01-01        51.5570       183460             15.6             -5.6   \n",
       "\n",
       "   month  day  primary_use_Education  \\\n",
       "0      1    1                      1   \n",
       "1      1    1                      1   \n",
       "2      1    1                      0   \n",
       "3      1    1                      0   \n",
       "4      1    1                      1   \n",
       "\n",
       "   primary_use_Entertainment/public assembly  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   primary_use_Food sales and service     ...      primary_use_Utility  \\\n",
       "0                                   0     ...                        0   \n",
       "1                                   0     ...                        0   \n",
       "2                                   0     ...                        0   \n",
       "3                                   0     ...                        0   \n",
       "4                                   0     ...                        0   \n",
       "\n",
       "   site_id_2  site_id_6  site_id_7  site_id_9  site_id_10  site_id_11  \\\n",
       "0          1          0          0          0           0           0   \n",
       "1          1          0          0          0           0           0   \n",
       "2          1          0          0          0           0           0   \n",
       "3          1          0          0          0           0           0   \n",
       "4          1          0          0          0           0           0   \n",
       "\n",
       "   site_id_13  site_id_14  site_id_15  \n",
       "0           0           0           0  \n",
       "1           0           0           0  \n",
       "2           0           0           0  \n",
       "3           0           0           0  \n",
       "4           0           0           0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time as index\n",
    "train_test.set_index('timestamp',inplace=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>primary_use_Education</th>\n",
       "      <th>primary_use_Entertainment/public assembly</th>\n",
       "      <th>primary_use_Food sales and service</th>\n",
       "      <th>primary_use_Healthcare</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use_Utility</th>\n",
       "      <th>site_id_2</th>\n",
       "      <th>site_id_6</th>\n",
       "      <th>site_id_7</th>\n",
       "      <th>site_id_9</th>\n",
       "      <th>site_id_10</th>\n",
       "      <th>site_id_11</th>\n",
       "      <th>site_id_13</th>\n",
       "      <th>site_id_14</th>\n",
       "      <th>site_id_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4.5719</td>\n",
       "      <td>72102</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            meter_reading  square_feet  air_temperature  dew_temperature  \\\n",
       "timestamp                                                                  \n",
       "2016-01-01         4.5719        72102             15.6             -5.6   \n",
       "\n",
       "            month  day  primary_use_Education  \\\n",
       "timestamp                                       \n",
       "2016-01-01      1    1                      1   \n",
       "\n",
       "            primary_use_Entertainment/public assembly  \\\n",
       "timestamp                                               \n",
       "2016-01-01                                          0   \n",
       "\n",
       "            primary_use_Food sales and service  primary_use_Healthcare  \\\n",
       "timestamp                                                                \n",
       "2016-01-01                                   0                       0   \n",
       "\n",
       "               ...      primary_use_Utility  site_id_2  site_id_6  site_id_7  \\\n",
       "timestamp      ...                                                             \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "\n",
       "            site_id_9  site_id_10  site_id_11  site_id_13  site_id_14  \\\n",
       "timestamp                                                               \n",
       "2016-01-01          0           0           0           0           0   \n",
       "\n",
       "            site_id_15  \n",
       "timestamp               \n",
       "2016-01-01           0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meter_reading', 'square_feet', 'air_temperature', 'dew_temperature',\n",
       "       'month', 'day', 'primary_use_Education',\n",
       "       'primary_use_Entertainment/public assembly',\n",
       "       'primary_use_Food sales and service', 'primary_use_Healthcare',\n",
       "       'primary_use_Lodging/residential',\n",
       "       'primary_use_Manufacturing/industrial', 'primary_use_Office',\n",
       "       'primary_use_Other', 'primary_use_Parking',\n",
       "       'primary_use_Public services', 'primary_use_Religious worship',\n",
       "       'primary_use_Retail', 'primary_use_Technology/science',\n",
       "       'primary_use_Utility', 'site_id_2', 'site_id_6', 'site_id_7',\n",
       "       'site_id_9', 'site_id_10', 'site_id_11', 'site_id_13', 'site_id_14',\n",
       "       'site_id_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the predictor and featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>primary_use_Education</th>\n",
       "      <th>primary_use_Entertainment/public assembly</th>\n",
       "      <th>primary_use_Food sales and service</th>\n",
       "      <th>primary_use_Healthcare</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_use_Utility</th>\n",
       "      <th>site_id_2</th>\n",
       "      <th>site_id_6</th>\n",
       "      <th>site_id_7</th>\n",
       "      <th>site_id_9</th>\n",
       "      <th>site_id_10</th>\n",
       "      <th>site_id_11</th>\n",
       "      <th>site_id_13</th>\n",
       "      <th>site_id_14</th>\n",
       "      <th>site_id_15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>98829</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>4.5719</td>\n",
       "      <td>72102</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>209.8860</td>\n",
       "      <td>553210</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>86323</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>51.5570</td>\n",
       "      <td>183460</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            meter_reading  square_feet  air_temperature  dew_temperature  \\\n",
       "timestamp                                                                  \n",
       "2016-01-01         0.0000        98829             15.6             -5.6   \n",
       "2016-01-01         4.5719        72102             15.6             -5.6   \n",
       "2016-01-01       209.8860       553210             15.6             -5.6   \n",
       "2016-01-01         0.0000        86323             15.6             -5.6   \n",
       "2016-01-01        51.5570       183460             15.6             -5.6   \n",
       "\n",
       "            month  day  primary_use_Education  \\\n",
       "timestamp                                       \n",
       "2016-01-01      1    1                      1   \n",
       "2016-01-01      1    1                      1   \n",
       "2016-01-01      1    1                      0   \n",
       "2016-01-01      1    1                      0   \n",
       "2016-01-01      1    1                      1   \n",
       "\n",
       "            primary_use_Entertainment/public assembly  \\\n",
       "timestamp                                               \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "2016-01-01                                          0   \n",
       "\n",
       "            primary_use_Food sales and service  primary_use_Healthcare  \\\n",
       "timestamp                                                                \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "2016-01-01                                   0                       0   \n",
       "\n",
       "               ...      primary_use_Utility  site_id_2  site_id_6  site_id_7  \\\n",
       "timestamp      ...                                                             \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "2016-01-01     ...                        0          1          0          0   \n",
       "\n",
       "            site_id_9  site_id_10  site_id_11  site_id_13  site_id_14  \\\n",
       "timestamp                                                               \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "2016-01-01          0           0           0           0           0   \n",
       "\n",
       "            site_id_15  \n",
       "timestamp               \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "2016-01-01           0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_test[['meter_reading']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_test['meter_reading']# delete target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test = train_test.values.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training-Validation Spearation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation-set (1000, 28) | Train-set (28999, 28)\n",
      "------------------------------------------------\n",
      "validation-target (1000, 1) | Train-Target (28999, 1)\n"
     ]
    }
   ],
   "source": [
    "#img_size=10;\n",
    "VALIDATION_SIZE = 1000\n",
    "\n",
    "validation_set = train_test[:VALIDATION_SIZE].values\n",
    "validation_target = target[:VALIDATION_SIZE].values\n",
    "\n",
    "train_set = train_test[VALIDATION_SIZE:].values\n",
    "train_target = target[VALIDATION_SIZE:].values\n",
    "\n",
    "print('validation-set',validation_set.shape, '|' ,'Train-set', train_set.shape)\n",
    "print('------------------------------------------------')\n",
    "print('validation-target',validation_target.shape,'|','Train-Target' ,train_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize(array):\n",
    "    '''\n",
    "    Standardize an array along eachcolumn (each feature that is)\n",
    "    '''\n",
    "    transformer = MaxAbsScaler().fit(array)\n",
    "    output = transformer.transform(array)\n",
    "    return  np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = Standardize(validation_set)\n",
    "validation_target = Standardize(validation_target)\n",
    "train_set = Standardize(train_set)\n",
    "train_target =  Standardize(train_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_set.astype(np.float64, copy=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set.astype(np.float64, copy=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 20000 on local environment to get 0.99 accuracy\n",
    "TRAINING_ITERATIONS = 200\n",
    "    \n",
    "DROPOUT = 0.5\n",
    "#BATCH_SIZES = 200\n",
    "\n",
    "# set to 0 to train on all available data\n",
    "\n",
    "BATCH_SIZE= 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_set.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_set\n",
    "    global train_target\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_set = train_set[perm]\n",
    "        train_target = train_target[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_set[start:end], train_target[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def valdation_random_sampler(validation_set, validation_target, n_validation_sample):    \n",
    "    rng = np.random.RandomState(42)  # reproducible results with a fixed seed\n",
    "    indices = random.sample(range(0, len(validation_set)-1), n_validation_sample)\n",
    "    #indices = np.arange(n_samples)\n",
    "    \n",
    "    rng.shuffle(indices)\n",
    "    #print(indices)\n",
    "    x_shuffled = validation_set[indices]\n",
    "    y_shuffled = validation_target[indices]\n",
    "    return x_shuffled,y_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= valdation_random_sampler(validation_set, validation_target,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Params\n",
    "with tf.name_scope(\"input_target_placeholders\"):    \n",
    "    input_dim = 1\n",
    "    ##The Input Layer as a Placeholder\n",
    "    #Since we will provide data sequentially, the 'batch size'\n",
    "    #is 1.\n",
    "    input_layer = tf.placeholder(tf.float32, [1, input_dim*train_set.shape[1]],name=\"input_data\")\n",
    "    correct_output = tf.placeholder(tf.float32, [input_dim],name=\"target_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f5ac025ceb8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"lstmLayer\",reuse=tf.AUTO_REUSE ):    \n",
    "    lstm_layer1 = rnn_cell.BasicLSTMCell(input_dim*1026,state_is_tuple=False)\n",
    "    #lstm_layer1 = rnn_cell.BasicLSTMCell(input_dim*1,state_is_tuple=True)\n",
    "\n",
    "    #The LSTM state as a Variable initialized to zeroes\n",
    "    lstm_state1 = tf.Variable(tf.zeros([1, lstm_layer1.state_size]),trainable=False,name=\"initial_state\")\n",
    "    #lstm_state1 = tf.Variable(lstm_layer1.zero_state(1,lstm_layer1.state_size[-1] ), trainable=False)\n",
    "    #Connect the input layer and initial LSTM state to the LSTM cell\n",
    "    lstm_output1, lstm_state_output1 = lstm_layer1(input_layer, lstm_state1)\n",
    "    #The LSTM state will get updated\n",
    "    outputs = lstm_state1.assign(lstm_state_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstmLayer_1/basic_lstm_cell/Mul_2:0' shape=(1, 1026) dtype=float32>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(1026)])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"weight_Bias_learning_rate\"):\n",
    "    global_step = tf.Variable(0, trainable=False,name=\"global_step\")\n",
    "    starter_learning_rate = 1e-6\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.8, staircase=False,name =\"Exponential_decay\")\n",
    "    ##The Regression-Output Layer\n",
    "    #The Weights and Biases matrices first\n",
    "    output_W1 = tf.Variable(tf.truncated_normal([int(lstm_output1.shape[1]), 1]),name=\"weight\")\n",
    "    output_b1 = tf.Variable(tf.truncated_normal([input_dim]),name=\"bias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"prediction\"):\n",
    "    #Compute the output\n",
    "    final_output = tf.matmul(lstm_output1, output_W1) + output_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lambda_l2_reg=0.5 \n",
    "l2 = lambda_l2_reg * sum( tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables() if not (\"noreg\" in tf_var.name or \"bias\" in tf_var.name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.name_scope(\"RMS_error\"):\n",
    "    ##Calculate the Sum-of-Squares Error\n",
    "    error = tf.pow(tf.subtract(final_output, correct_output), 2)+l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"optimizer\",reuse=tf.AUTO_REUSE ):    \n",
    "    ##The Optimizer\n",
    "    #Adam works best\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary to monitor MSE\n",
    "mse=tf.summary.tensor_summary(\"errors_Summary\",error)\n",
    "# Create a summary to monitor  predictions\n",
    "prediction=tf.summary.tensor_summary(\"predictions_Summmary\", final_output)\n",
    "# Create a summary to monitor bias\n",
    "bias_vec=tf.summary.tensor_summary(\"bias\", output_b1)\n",
    "# create sumary\n",
    "#rate_vec=tf.summary.scalar(\"rate\", learning_rate)\n",
    "\n",
    "\n",
    "#histogram plot\n",
    "\n",
    "error_stats=tf.summary.histogram(\"errors_Histogram\",error)\n",
    "weight_stats=tf.summary.histogram(\"weights_Histogram\",output_W1)\n",
    "bias_stats=tf.summary.histogram(\"biases_Histogram\",output_b1)\n",
    "#learning_stats=tf.histogram_summary(\"biases_Histogram\",learning_rate)\n",
    "\n",
    "\n",
    "#merged_summary_op =  tf.merge_all_summaries()\n",
    "merged_summary_op =   tf.summary.merge([mse,prediction,bias_vec,error_stats,weight_stats,bias_stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Session\n",
    "sess = tf.Session()\n",
    "#Initialize all Variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = './lstm/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter\n",
    "train_errors = []\n",
    "train_prediction = []\n",
    "validation_errors = []\n",
    "validation_prediction= []\n",
    "display_step = 1\n",
    "VALIDATON= True\n",
    "\n",
    "n_validation_sample = 50\n",
    "writer = tf.summary.FileWriter(logs_path, graph= tf.get_default_graph())\n",
    "TRAINING_ITERATIONS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_mse / validation_mse => 817.43 / 816.47 for step 0\n",
      "training_mse / validation_mse => 816.49 / 815.74 for step 1\n",
      "training_mse / validation_mse => 815.65 / 815.03 for step 2\n",
      "training_mse / validation_mse => 814.86 / 814.30 for step 3\n",
      "training_mse / validation_mse => 814.02 / 813.61 for step 4\n",
      "training_mse / validation_mse => 813.34 / 812.86 for step 5\n",
      "training_mse / validation_mse => 812.51 / 812.13 for step 6\n",
      "training_mse / validation_mse => 811.79 / 811.42 for step 7\n",
      "training_mse / validation_mse => 811.09 / 810.70 for step 8\n",
      "training_mse / validation_mse => 810.48 / 810.01 for step 9\n",
      "training_mse / validation_mse => 809.72 / 809.26 for step 10\n",
      "training_mse / validation_mse => 808.98 / 808.58 for step 11\n",
      "training_mse / validation_mse => 808.69 / 807.84 for step 12\n",
      "training_mse / validation_mse => 807.60 / 807.13 for step 13\n",
      "training_mse / validation_mse => 806.81 / 806.42 for step 14\n",
      "training_mse / validation_mse => 806.22 / 805.71 for step 15\n",
      "training_mse / validation_mse => 805.69 / 805.00 for step 16\n",
      "training_mse / validation_mse => 804.78 / 804.31 for step 17\n",
      "training_mse / validation_mse => 803.95 / 803.58 for step 18\n",
      "training_mse / validation_mse => 803.26 / 802.88 for step 19\n",
      "training_mse / validation_mse => 802.55 / 802.18 for step 20\n",
      "training_mse / validation_mse => 802.23 / 801.47 for step 21\n",
      "training_mse / validation_mse => 801.41 / 800.79 for step 22\n",
      "training_mse / validation_mse => 800.68 / 800.07 for step 23\n",
      "training_mse / validation_mse => 799.85 / 799.38 for step 24\n",
      "training_mse / validation_mse => 799.11 / 798.67 for step 25\n",
      "training_mse / validation_mse => 798.49 / 797.99 for step 26\n",
      "training_mse / validation_mse => 797.80 / 797.30 for step 27\n",
      "training_mse / validation_mse => 797.00 / 796.60 for step 28\n",
      "training_mse / validation_mse => 796.26 / 795.95 for step 29\n",
      "training_mse / validation_mse => 795.58 / 795.23 for step 30\n",
      "training_mse / validation_mse => 775.27 / 774.81 for step 60\n",
      "training_mse / validation_mse => 755.56 / 755.17 for step 90\n",
      "training_mse / validation_mse => 736.60 / 736.28 for step 120\n",
      "training_mse / validation_mse => 718.36 / 718.07 for step 150\n",
      "training_mse / validation_mse => 700.92 / 700.50 for step 180\n",
      "training_mse / validation_mse => 689.96 / 689.68 for step 199\n"
     ]
    }
   ],
   "source": [
    "#update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "for i in range(TRAINING_ITERATIONS):\n",
    "\n",
    "        #get new batch\n",
    "        batch_xs, batch_ys = next_batch(BATCH_SIZE)  \n",
    "        #print(batch_ys.shape,batch_xs.shape)\n",
    "        temp = [] # store output temporally\n",
    "        for m,n in zip(batch_xs,batch_ys):\n",
    "            #print(m.shape,n.shape)\n",
    "            # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "            _, _, network_output,errors,summary = sess.run([outputs,\n",
    "                                         train_step,\n",
    "                                         final_output,error,merged_summary_op],\n",
    "                                        feed_dict = {\n",
    "                                            input_layer: m.reshape(1,train_set.shape[1]),\n",
    "                                            correct_output: n})\n",
    "            \n",
    "        \n",
    "            writer.add_summary(summary)\n",
    "            temp.append(errors)\n",
    "            train_prediction.append(network_output) # store predicted value\n",
    "            \n",
    "        error_mean = np.mean(temp)                  \n",
    "        train_errors.append(error_mean)\n",
    "               \n",
    "        if(VALIDATON):\n",
    "            val_train, val_tar = valdation_random_sampler(validation_set, validation_target, n_validation_sample)\n",
    "            temp_ = []\n",
    "            for k,l in zip(val_train,val_tar):\n",
    "                sess.run(lstm_state1.assign(tf.zeros([1, lstm_layer1.state_size])))\n",
    "\n",
    "                final_outputs, val_error = sess.run([\n",
    "                                          final_output, error],\n",
    "                                         feed_dict = {\n",
    "                                         input_layer: k.reshape(1,train_set.shape[1]),\n",
    "                                         correct_output: l})  \n",
    "                \n",
    "                validation_prediction.append(final_outputs)\n",
    "                temp_.append(val_error)\n",
    "                 \n",
    "            val_error_mean = np.mean(temp_)\n",
    "            validation_errors.append(val_error_mean)\n",
    "                            \n",
    "            if i%display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n",
    "                print('training_mse / validation_mse => %.2f / %.2f for step %d' % \n",
    "            (error_mean, val_error_mean, i))\n",
    "              \n",
    "            \n",
    "                \n",
    "        \n",
    "        # increase display_step\n",
    "        \n",
    "        # increase display_step                       \n",
    "        if i%(display_step*30) == 0 and i:\n",
    "            display_step *= 30\n",
    "        \n",
    "        # train on batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorplot = np.array(train_errors) # make errors into arrays\n",
    "errorplot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Training epoch')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errorplot, 'o--', linewidth=2,color='orange')\n",
    "plt.title(\"Histogram  error plot\",fontweight='bold')\n",
    "plt.ylabel(\"Error\",fontweight='bold')\n",
    "plt.xlabel(\"Training epoch\",fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "LSTM works fine on Time series but one needs care so that things do not blow up.\n",
    "On a very suphiscated machine, this model could work impeccably well.\n",
    "ARIMA,SARIMA are also very powerful models but they have less representational power compared to lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
